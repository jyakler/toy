{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f7f0b8-3be9-47f9-b0a4-4f62ecfc3716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusersNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading diffusers-0.14.0-py3-none-any.whl (737 kB)\n",
      "     -------------------------------------- 737.4/737.4 kB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-metadata in d:\\anaconda\\lib\\site-packages (from diffusers) (4.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from diffusers) (2021.8.3)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from diffusers) (1.24.1)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from diffusers) (3.3.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from diffusers) (2.26.0)\n",
      "Requirement already satisfied: Pillow in d:\\anaconda\\lib\\site-packages (from diffusers) (8.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.10.0 in d:\\anaconda\\lib\\site-packages (from diffusers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from huggingface-hub>=0.10.0->diffusers) (6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\anaconda\\lib\\site-packages (from importlib-metadata->diffusers) (3.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->diffusers) (2021.10.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.10.0->diffusers) (3.0.4)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.10.0->diffusers) (0.4.4)\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.14.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8986a088-f76f-42fe-9c6b-60fc1d833922",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c6c53e-4ef2-4a53-9ca4-6322cc83e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch_device=\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9413cc-4251-4860-a57c-b29dab973642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPMSolverMultistepScheduler {\n",
       "  \"_class_name\": \"DPMSolverMultistepScheduler\",\n",
       "  \"_diffusers_version\": \"0.14.0\",\n",
       "  \"algorithm_type\": \"dpmsolver++\",\n",
       "  \"beta_end\": 0.012,\n",
       "  \"beta_schedule\": \"scaled_linear\",\n",
       "  \"beta_start\": 0.00085,\n",
       "  \"clip_sample\": false,\n",
       "  \"dynamic_thresholding_ratio\": 0.995,\n",
       "  \"lower_order_final\": true,\n",
       "  \"num_train_timesteps\": 1000,\n",
       "  \"prediction_type\": \"v_prediction\",\n",
       "  \"sample_max_value\": 1.0,\n",
       "  \"set_alpha_to_one\": false,\n",
       "  \"skip_prk_steps\": true,\n",
       "  \"solver_order\": 2,\n",
       "  \"solver_type\": \"midpoint\",\n",
       "  \"steps_offset\": 1,\n",
       "  \"thresholding\": false,\n",
       "  \"trained_betas\": null\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20f0d1eb-8594-49b4-b0b7-c7d34adca8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "text_encoder\\model.safetensors not found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e475f85b40894d6b8f289c722f2c0584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\transformers\\models\\clip\\feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "model_id=\"stabilityai/stable-diffusion-2-1\"\n",
    "\n",
    "# Use the DPMSolverMultistepScheduler (DPM-Solver++) scheduler here instead\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81bc3a85-3104-46d2-9423-5a2f69a94420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xformersNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading xformers-0.0.16-cp39-cp39-win_amd64.whl (40.0 MB)\n",
      "     ---------------------------------------- 40.0/40.0 MB 9.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from xformers) (1.22.0)\n",
      "Collecting pyre-extensions==0.0.23\n",
      "  Downloading pyre_extensions-0.0.23-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: torch==1.13.1 in d:\\anaconda\\lib\\site-packages (from xformers) (1.13.1)\n",
      "Collecting typing-inspect\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: typing-extensions in d:\\anaconda\\lib\\site-packages (from pyre-extensions==0.0.23->xformers) (4.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anaconda\\lib\\site-packages (from typing-inspect->pyre-extensions==0.0.23->xformers) (0.4.3)\n",
      "Installing collected packages: typing-inspect, pyre-extensions, xformers\n",
      "Successfully installed pyre-extensions-0.0.23 typing-inspect-0.8.0 xformers-0.0.16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install -U xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f54cfd1-c446-467e-84cf-778aecb0021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[diffusers.schedulers.scheduling_ddpm.DDPMScheduler,\n",
       " diffusers.schedulers.scheduling_lms_discrete.LMSDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_dpmsolver_multistep.DPMSolverMultistepScheduler,\n",
       " diffusers.schedulers.scheduling_dpmsolver_singlestep.DPMSolverSinglestepScheduler,\n",
       " diffusers.schedulers.scheduling_pndm.PNDMScheduler,\n",
       " diffusers.schedulers.scheduling_deis_multistep.DEISMultistepScheduler,\n",
       " diffusers.schedulers.scheduling_euler_discrete.EulerDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_heun_discrete.HeunDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_ddim.DDIMScheduler,\n",
       " diffusers.schedulers.scheduling_k_dpm_2_discrete.KDPM2DiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler,\n",
       " diffusers.schedulers.scheduling_k_dpm_2_ancestral_discrete.KDPM2AncestralDiscreteScheduler,\n",
       " diffusers.schedulers.scheduling_euler_ancestral_discrete.EulerAncestralDiscreteScheduler]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.scheduler.compatibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f77fc6-79d4-4c74-a634-ca3c7a2b6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4185fc2-4039-453d-a7f3-99f67fe468df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image                                                                                                                                                                                                                         \n",
    "\n",
    "def image_grid(imgs, rows=2, cols=2):                                                                                                                                                                                                         \n",
    "    w, h = imgs[0].size                                                                                                                                                                                                                       \n",
    "    grid = Image.new('RGB', size=(cols*w, rows*h))                                                                                                                                                                                            \n",
    "                                                                                                                                                                                                                                              \n",
    "    for i, img in enumerate(imgs):                                                                                                                                                                                                            \n",
    "        grid.paste(img, box=(i%cols*w, i//cols*h))                                                                                                                                                                                            \n",
    "    return grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d4444d8-94cd-4eff-8423-9b5a645c5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs(batch_size=1):                                                                                                                                                                                                                 \n",
    "  generator = [torch.Generator(\"cuda\").manual_seed(i) for i in range(batch_size)]                                                                                                                                                             \n",
    "  prompts = batch_size * [prompt]                                                                                                                                                                                                             \n",
    "  num_inference_steps = 20                                                                                                                                                                                                                    \n",
    "\n",
    "  return {\"prompt\": prompts, \"generator\": generator, \"num_inference_steps\": num_inference_steps}                                                                                                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc73781-ea72-4329-9297-2230a0f03f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f41cb7dec14f0aaf0b4e48f6b62174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 3.16 GiB (GPU 0; 8.00 GiB total capacity; 6.20 GiB already allocated; 0 bytes free; 6.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9440/85648646.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# negative_prompt=input(\"negative: \")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnegative_prompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mget_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mimage_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, prompt, height, width, num_inference_steps, guidance_scale, negative_prompt, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                 \u001b[1;31m# predict the noise residual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m                 noise_pred = self.unet(\n\u001b[0m\u001b[0;32m    668\u001b[0m                     \u001b[0mlatent_model_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\diffusers\\models\\unet_2d_condition.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, down_block_additional_residuals, mid_block_additional_residual, return_dict)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdownsample_block\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdown_blocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownsample_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"has_cross_attention\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdownsample_block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_cross_attention\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m                 sample, res_samples = downsample_block(\n\u001b[0m\u001b[0;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m                     \u001b[0mtemb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\diffusers\\models\\unet_2d_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, temb, encoder_hidden_states, attention_mask, cross_attention_kwargs)\u001b[0m\n\u001b[0;32m    835\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m                 \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 837\u001b[1;33m                 hidden_states = attn(\n\u001b[0m\u001b[0;32m    838\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\diffusers\\models\\transformer_2d.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, encoder_hidden_states, timestep, class_labels, cross_attention_kwargs, return_dict)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;31m# 2. Blocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_blocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m             hidden_states = block(\n\u001b[0m\u001b[0;32m    266\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\diffusers\\models\\attention.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, encoder_hidden_states, timestep, attention_mask, cross_attention_kwargs, class_labels)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;31m# 1. Self-Attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0mcross_attention_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_attention_kwargs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcross_attention_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m         attn_output = self.attn1(\n\u001b[0m\u001b[0;32m    292\u001b[0m             \u001b[0mnorm_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monly_cross_attention\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\diffusers\\models\\cross_attention.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, encoder_hidden_states, attention_mask, **cross_attention_kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;31m# here we simply pass along all tensors to the selected processor class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;31m# For standard processors that are defined here, `**cross_attention_kwargs` is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         return self.processor(\n\u001b[0m\u001b[0;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\diffusers\\models\\cross_attention.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, attn, hidden_states, encoder_hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead_to_batch_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mattention_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attention_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_to_head_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\diffusers\\models\\cross_attention.py\u001b[0m in \u001b[0;36mget_attention_scores\u001b[1;34m(self, query, key, attention_mask)\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         attention_scores = torch.baddbmm(\n\u001b[0m\u001b[0;32m    243\u001b[0m             \u001b[0mbaddbmm_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.16 GiB (GPU 0; 8.00 GiB total capacity; 6.20 GiB already allocated; 0 bytes free; 6.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# prompt=input(\"prompt: \")\n",
    "prompt=\"portrait photo of a old warrior chief\"\n",
    "# negative_prompt=input(\"negative: \")\n",
    "negative_prompt=\"\"\n",
    "images=pipe(**get_inputs(batch_size=1)).images\n",
    "\n",
    "image_grid(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5fa469-08dd-4590-bf79-3ec85bd27ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
